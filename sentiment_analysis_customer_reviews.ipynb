{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46e51b46-4e59-426e-9cfa-b4fe6bf6ffbe",
   "metadata": {},
   "source": [
    "Created by: Viktor Hatina\n",
    "Date: April 18, 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26fdfa68-a882-4afc-a6c6-8f23073bd932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7889dc81-0138-4e89-b69c-cb60b5daad91",
   "metadata": {},
   "source": [
    "\n",
    "# Experiment Sentiment Analysis on Customer Feedback and Reviews\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175b533d-5f16-451a-b581-96627895803e",
   "metadata": {},
   "source": [
    "## Description of used data\n",
    "This dataset contains customer sentiments expressed in various sources such as social media, review platforms, testimonials, and more. The dataset includes text, sentiment (positive or negative), source of the sentiment, date/time of the sentiment, user ID, location, and confidence score. The sentiments reflect customers' opinions and experiences with products, services, movies, music, books, restaurants, websites, customer support, and more\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90ece9e3-a477-47c1-b14e-d229541b0fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text, Sentiment, Source, Date/Time, User ID, Location, Confidence Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"I love this product!\", Positive, Twitter, 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"The service was terrible.\", Negative, Yelp Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"This movie is amazing!\", Positive, IMDb, 2023...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"I'm so disappointed with their customer suppo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Just had the best meal of my life!\", Positive...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Text, Sentiment, Source, Date/Time, User ID, Location, Confidence Score\n",
       "0  \"I love this product!\", Positive, Twitter, 202...                     \n",
       "1  \"The service was terrible.\", Negative, Yelp Re...                     \n",
       "2  \"This movie is amazing!\", Positive, IMDb, 2023...                     \n",
       "3  \"I'm so disappointed with their customer suppo...                     \n",
       "4  \"Just had the best meal of my life!\", Positive...                     "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset                     \n",
    "df = pd.read_csv(\"sentiment-analysis.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67f59821-6823-45cb-be15-d6f03945a7ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Source</th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>User ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Confidence Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"I love this product!\"</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>2023-06-15 09:23:14</td>\n",
       "      <td>@user123</td>\n",
       "      <td>New York</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"The service was terrible.\"</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Yelp Reviews</td>\n",
       "      <td>2023-06-15 11:45:32</td>\n",
       "      <td>user456</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"This movie is amazing!\"</td>\n",
       "      <td>Positive</td>\n",
       "      <td>IMDb</td>\n",
       "      <td>2023-06-15 14:10:22</td>\n",
       "      <td>moviefan789</td>\n",
       "      <td>London</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"I'm so disappointed with their customer suppo...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Online Forum</td>\n",
       "      <td>2023-06-15 17:35:11</td>\n",
       "      <td>forumuser1</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Just had the best meal of my life!\"</td>\n",
       "      <td>Positive</td>\n",
       "      <td>TripAdvisor</td>\n",
       "      <td>2023-06-16 08:50:59</td>\n",
       "      <td>foodie22</td>\n",
       "      <td>Paris</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Sentiment  \\\n",
       "0                             \"I love this product!\"   Positive   \n",
       "1                        \"The service was terrible.\"   Negative   \n",
       "2                           \"This movie is amazing!\"   Positive   \n",
       "3  \"I'm so disappointed with their customer suppo...   Negative   \n",
       "4               \"Just had the best meal of my life!\"   Positive   \n",
       "\n",
       "          Source             Date/Time       User ID      Location  \\\n",
       "0        Twitter   2023-06-15 09:23:14      @user123      New York   \n",
       "1   Yelp Reviews   2023-06-15 11:45:32       user456   Los Angeles   \n",
       "2           IMDb   2023-06-15 14:10:22   moviefan789        London   \n",
       "3   Online Forum   2023-06-15 17:35:11    forumuser1       Toronto   \n",
       "4    TripAdvisor   2023-06-16 08:50:59      foodie22         Paris   \n",
       "\n",
       "  Confidence Score  \n",
       "0             0.85  \n",
       "1             0.65  \n",
       "2             0.92  \n",
       "3             0.78  \n",
       "4             0.88  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Clean the dataset and separate the data into columns\n",
    "data=df['Text, Sentiment, Source, Date/Time, User ID, Location, Confidence Score'].str.split(',', expand=True)\n",
    "data.columns=['Text', 'Sentiment', 'Source', 'Date/Time', 'User ID', 'Location', 'Confidence Score']\n",
    "data = data.dropna() # remove empty cells\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81b1f25-cb01-4588-8a42-e3ce28b23e2f",
   "metadata": {},
   "source": [
    "\n",
    "Sentiment analysis, also known as opinion mining, is a natural language processing (NLP) technique used to determine the sentiment or emotional tone expressed in a piece of text, such as a review, comment, tweet, or customer feedback\n",
    "The primary goal of sentiment analysis is to understand the writer's attitude or opinion towards a particular subject, entity, or topic mentioned in the text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1237b0a3-2df6-4dd2-99b4-546fbf8ee7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take relevant columns such as text (feature) and sentiment (target) to use for splitting the dataset\n",
    "X = data['Text'].astype(str)\n",
    "y = data['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c689251-4bfd-496b-9264-3100d7b97815",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Engineering\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "X_vec = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed52df9-7043-45c5-8b93-01acb85a1b26",
   "metadata": {},
   "source": [
    "\n",
    "Vectorization phase in sentiment analysis converts raw text data into numerical representations, enabling machine learning algorithms to process and analyze text data effectively\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64bcce41-6bb8-4c9c-974f-4032514e5b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train and test samples\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vec, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66c65e8c-4ff5-4100-8b7b-21b06a0cb79b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Selection and Training\n",
    "model = LinearSVC()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89b1721-5dd0-4d81-9303-af666982a344",
   "metadata": {},
   "source": [
    "\n",
    "### Other models include\n",
    "1. Linear Support Vector Classifier\n",
    "2. Logistic regression - particularly suitable for binary classification of tasks\n",
    "3. Random Forest and gradient boosting\n",
    "4. Deep Learning Models..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b87e597e-5e2d-4137-8523-5dd3d83de3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess the user input and make predictions\n",
    "def predict_sentiment(input_text):\n",
    "    print(\"Text obtained: \", input_text)\n",
    "    # Preprocess the input text\n",
    "    input_vec = vectorizer.transform([input_text])\n",
    "    \n",
    "    print(\"Text Vectorised: \", input_vec)\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(input_vec)\n",
    "    print(\"Models Prediction: \", prediction)\n",
    "    # Return the prediction\n",
    "    return \"Positive\" if prediction[0] == ' Positive' else \"Negative\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9adf441-6fe4-4ea5-8357-5c6e0bf0f6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.62      1.00      0.77         5\n",
      "    Positive       1.00      0.80      0.89        15\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.81      0.90      0.83        20\n",
      "weighted avg       0.91      0.85      0.86        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27d16282-8c97-4e12-ab87-69ef91bee07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 5  0]\n",
      " [ 3 12]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b113b3-2337-4bd2-9755-69c3aa71aebe",
   "metadata": {},
   "source": [
    "\n",
    "Explanation of Classification Report:\n",
    "Precision: Precision measures the proportion of true positive predictions among all positive predictions. It indicates how often the model correctly predicts positive instances.\n",
    "Recall: Recall measures the proportion of true positive predictions among all actual positive instances. It indicates the model's ability to correctly identify positive instances.\n",
    "F1-score: The F1-score is the harmonic mean of precision and recall, providing a balance between the two metrics. It's useful for evaluating models when there's an imbalance between classes.\n",
    "Support: Support is the number of actual occurrences of each class in the test set. It provides context for the precision, recall, and F1-score metrics.\n",
    "Explanation of Confusion Matrix:\n",
    "The confusion matrix is a summary of the model's predictions compared to the actual labels.\n",
    " - True Positive (TP) top left: The model correctly predicted positive instances as positive.\n",
    " - False Positive (FP) top right: The model incorrectly predicted negative instances as positive.\n",
    " - True Negative (TN) bottom right: The model correctly predicted negative instances as negative.\n",
    " - False Negative (FN) bottom left: The model incorrectly predicted positive instances as negative.\n",
    "\n",
    "Additional Insights:\n",
    "- A high accuracy score indicates that the model is correctly classifying a large portion of instances.\n",
    "- Precision and recall scores provide insights into the model's performance for each class, helping to understand its strengths and weaknesses.\n",
    "- The confusion matrix provides a detailed breakdown of correct and incorrect predictions, aiding in understanding where the model is making errors.\n",
    "- Consideration of these metrics and insights can inform further improvements to the model, such as refining features, adjusting hyperparameters, or collecting more diverse training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb308e36-00e8-423a-ac14-018d1c75bb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the sentiment analysis interface!\n",
      "Type 'exit' to quit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your comment (type 'exit' to quit):  this was bad service\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text obtained:  this was bad service\n",
      "Text Vectorised:    (0, 161)\t1.0\n",
      "Models Prediction:  [' Negative']\n",
      "Predicted Sentiment: Negative\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your comment (type 'exit' to quit):  I am very happy!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text obtained:  I am very happy!\n",
      "Text Vectorised:  \n",
      "Models Prediction:  [' Positive']\n",
      "Predicted Sentiment: Positive\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your comment (type 'exit' to quit):  The agent was very helpful. Thanks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text obtained:  The agent was very helpful. Thanks\n",
      "Text Vectorised:    (0, 83)\t1.0\n",
      "Models Prediction:  [' Positive']\n",
      "Predicted Sentiment: Positive\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your comment (type 'exit' to quit):  The service was poor and I did not get the information needed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text obtained:  The service was poor and I did not get the information needed\n",
      "Text Vectorised:    (0, 161)\t0.341678089136951\n",
      "  (0, 133)\t0.4874860448469688\n",
      "  (0, 119)\t0.5681608220755726\n",
      "  (0, 90)\t0.5681608220755726\n",
      "Models Prediction:  [' Negative']\n",
      "Predicted Sentiment: Negative\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your comment (type 'exit' to quit):  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Interface loop\n",
    "print(\"Welcome to the sentiment analysis interface!\")\n",
    "print(\"Type 'exit' to quit.\")\n",
    "while True:\n",
    "    user_input = input(\"Enter your comment (type 'exit' to quit): \")\n",
    "    if user_input.lower() == 'exit':\n",
    "        print(\"Exiting...\")\n",
    "        break\n",
    "    else:\n",
    "        predicted_sentiment = predict_sentiment(user_input)\n",
    "        print(\"Predicted Sentiment:\", predicted_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca4afe6-fe12-44da-aa27-c0605b19d783",
   "metadata": {},
   "source": [
    "\n",
    "# Thank you "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8afd85-e17e-4e6f-b34c-83525cc4f732",
   "metadata": {},
   "source": [
    "### Next Steps:\n",
    "1. Improve model performance by training it on more data\n",
    "2. Evaluate broader model\n",
    "3. Test on official dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8831622-e3f4-4428-914e-bf50366f05ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
